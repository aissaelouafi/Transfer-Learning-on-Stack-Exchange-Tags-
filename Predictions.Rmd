---
title: "Stack Exhange tags prediction"
output: html_notebook
---
The goal of this [Kaggle](https://www.kaggle.com/c/transfer-learning-on-stack-exchange-tags) fun competition is to predict Stack Exchange tags based on Transfer Learning approach. In this competition, we provide the titles, text, and tags of Stack Exchange questions from six different site.

The challenge of this competition is to learn appropriate <b>physics </b>tags from others topic (travel, biology, cooking, robotic, crypto and tiy).

I will try to solve this problem using a classic text mining approach, I will try different Machine Learning approach. I will try also to use the [`sparklyr`](http://spark.rstudio.com/) library, It's a R Apache Spark interface.

#### Libraries installation 
```{r}
library(sparklyr)
library(dplyr)
library(ggplot2)
library(plotly)
library(stringr)
library(plotly)
library(tm)
library(wordcloud)
library(e1071) #Naive bayes classifier 
library(stats)
library(factoextra) # PCA 
```

#### Import data 

For memory issue (laptop with only 4Gb of RAM) I will analyze only first 1000 observations of each topic, it's about only <b>~10%</b> of real data ! Kaggle provide also a test dataset with 81926 observations talking about physics. Each dataframe contains 4 colmuns (id, title, content and tags column for the train data).
```{r}
biology =  read.csv("../biology.csv",nrows =1000)
travel = read.csv("../travel.csv",nrows=1000) 
robotic = read.csv("../robotics.csv",nrows=1000)
cooking = read.csv("../cooking.csv",nrows=1000)
crypto = read.csv("../crypto.csv",nrows=1000)
diy = read.csv("../diy.csv",nrows=1000)
test = read.csv("../test.csv",nrows=1000)
sample_submission = read.csv("../sample_submission.csv",nrows=1000)
```
#### Explore data

Lets explore the train dataset of multiple topics ! 

```{r}
travel[1:5,]
```

As I said before, every train `dataframe` contains 4 colmuns, <b>id, title, content and tags</b>. The test `dataframe` contains only <b>id, title and content</b> colmun to be predicted is <b>tags</b>. Every observations contains many tags, So we should predict multiple tags of every document.

The test data that will be used to evaluate our model contains documents about <b>physics</b>, So we should predict physics tags from non physics topic. Lets show the 5 first document of test `dataframe` : 

```{r}
test[1:5,]
```

#### Data exploration and visualization 
After showing the `dataframe`, I noticed that most of the time, the searched tag is contained in the title of the document. So we will start by analyzing documents titles and compare them with tags. Lets show the most frequent tags and comapre them to the most frequent word in the title corpus. We will count distinct tags frequency of every topic. 

```{r}
countDistinctTags <- function(df,nFreq){
  df <- as.data.frame(as.factor(unlist(str_split(df$tags," "))))
  colnames(df) <- c("tags")
  df <- data.frame(table(df$tags))
  colnames(df) <- c("tags","Freq")
  df <- df[order(df$Freq,decreasing = TRUE),]
  df <- df[1:nFreq,]
  return(df)
}
```

`countDistinctTags(df,nFreq)` count the distinct tags frequency with a minimal frequency `nFreq` on the `df` datafram. This function return a `dataframe` of tags frequency. So lets plot the 50 tags the most frequently tags.

```{r}
t <- countDistinctTags(travel,50)
t
```